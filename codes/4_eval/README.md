# Eval

- [configを変えます](./llm-leaderboard/configs/config.yaml)
- [設定はこちら](https://note.com/kan_hatakeyama/n/nbea55ed4498d#346033a9-c5c1-4527-90d1-24d07bfee450)

~~~
conda activate llmeval
cd llm-leaderboard/
python scripts/run_eval.py
python scripts/run_eval_wo_mtbench.py # mtbenchはgpt apiでの評価が必要なので､やらないバージョン
~~~

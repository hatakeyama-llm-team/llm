{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 種々のdatasetをintagrateします\n",
    "# 動作確認用です｡最新版はintegrate_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_path': '../../data/integrated_text.jsonl', 'max_records': 50000}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "    conf= yaml.safe_load(file)\n",
    "output_path=conf[\"output_path\"]\n",
    "max_records=conf[\"max_records\"]\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここでは例として､日英のwikipediaを読み込んでみます\n",
    "\n",
    "#TODO: よく考えると､これだとRAMが足りなくなるかも?\n",
    "dataset_list = [\n",
    "    load_dataset(\"hpprc/wikipedia-20240101\", split=\"train\").shuffle(), #日本語\n",
    "    #load_dataset(\"wikipedia\", \"20220301.en\",split=\"train\").shuffle(), #英語\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '4019422', 'url': 'https://ja.wikipedia.org/wiki/%E6%B8%A1%E8%BE%BA%E5%A4%A7%E8%BC%94%20%28%E9%99%B8%E4%B8%8A%E9%81%B8%E6%89%8B%29', 'title': '渡辺大輔 (陸上選手)', 'text': '渡辺 大輔（渡邉 大輔、わたなべ だいすけ、1975年5月29日 - ）は、日本の陸上競技選手である。\\n\\n八王子学園八王子高等学校、日本大学を経て、ミズノに所属。2000年シドニーオリンピックに男子走幅跳で出場した。 \\n\\n現在は母校・八王子高校の体育教諭で、同校陸上競技部の顧問・監督を務めており、甥（妻の姉の息子）にあたる橋岡優輝にも指導を行っていた。\\n\\n参照資料 \\n\\n日本の陸上競技指導者\\nオリンピック陸上競技日本代表選手\\n世界陸上選手権日本代表選手\\n日本の男子走幅跳の選手\\n日本の中等教育の教員\\n八王子学園八王子高等学校出身の人物\\n日本大学出身の人物\\n1975年生\\n存命人物'}\n"
     ]
    }
   ],
   "source": [
    "#datasetの中身を確認してみます｡\n",
    "#各recordは辞書形式になっています｡大切なのは､ textです｡\n",
    "for data in dataset_list[0]:\n",
    "    break\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsonl file ../../data/integrated_text.jsonl already exists. Overwrite? (y/n)\n",
      "overwriting files...\n",
      "Dataset({\n",
      "    features: ['id', 'url', 'title', 'text'],\n",
      "    num_rows: 1395760\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 50000/1395760 [00:04<01:48, 12410.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# 各datasetをmergeして､一つのjsonlにまとめます｡\n",
    "# ファイルは output_pathに生成されます\n",
    "# 各datasetは予めクリーニング, dedupされている必要があります｡\n",
    "#TODO: BTMのため､ジャンル別にデータを並べ替えたい\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"jsonl file {output_path} already exists. Overwrite? (y/n)\")\n",
    "    ans=input()\n",
    "\n",
    "    if ans==\"y\" or \"Y\":\n",
    "        overwrite=True\n",
    "        print(\"overwriting files...\")\n",
    "        with open(output_path,\"w\") as f:\n",
    "            f.write(\"\")\n",
    "    else:\n",
    "        overwrite=False\n",
    "        print(\"aborted.\")\n",
    "if overwrite:\n",
    "    with open(output_path,\"a\") as f:\n",
    "        for dataset in dataset_list:\n",
    "            print(dataset)\n",
    "            cnt=0\n",
    "            for data in tqdm(dataset):\n",
    "                out_text=json.dumps({\"text\":data[\"text\"]}, ensure_ascii=False)\n",
    "                #jsonlで書き出し\n",
    "\n",
    "                f.write(out_text+\"\\n\") \n",
    "\n",
    "                cnt+=1\n",
    "                if cnt>max_records:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 1395760\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatakeyama/miniconda3/envs/llmeval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#作ったモデルを動かしてみる\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "def perplexity(model, tokenizer, text) -> torch.Tensor:\n",
    "    tokenized_input = tokenizer.encode(\n",
    "        text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        output = model(tokenized_input, labels=tokenized_input)\n",
    "    ppl = torch.exp(output.loss)\n",
    "    return ppl.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatakeyama/miniconda3/envs/llmeval/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_path=\"../../models/hf\"\n",
    "model_path=\"../../models/hf_fin\"\n",
    "#model_path=\"../../models/hf_fin_shuffle\"\n",
    "#model_path=\"../../models/hf_10000\"\n",
    "model_path=\"../../models/hf/0312wiki300m_grad_en_to_ja_fin\"\n",
    "model_path=\"../../models/hf/0313wiki300m_grad_en_to_ja_fin_65k_vocab\"\n",
    "model_path=\"../../models/hf/0314gpt_mc4_wiki_en\"\n",
    "model_path=\"../../models/hf/0316mc4_wiki_en_wiki_jap\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=pipeline('text-generation',model=model,tokenizer=tokenizer, max_new_tokens=200, repetition_penalty=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  今日はいい\n",
      "perplexity:  1888.37646484375\n",
      "time:  3.5476720333099365\n",
      "time/character:  0.008386931520827274\n",
      "output:  今日はいいお天気ですね。\n",
      "さて、今日の午前中は、午後から「第2回 防災士試験」の日です!\n",
      "私は、この日の午前に、「防災士試験(平成19年度)」を受けてきましたが・・・\n",
      "合格したのは、3名でした・・・。\n",
      "まず、私が受けたのは、防災士の資格を持つ方でしたので、その方の話を聞いてみました。「防災士って資格があるんだ!」と実感しましたし、私自身も、防災士になりたいと思いましたので、勉強になりました。\n",
      "そして、もう一つ驚いたのが、私の受ける学科では、防災士を受験する人が少なかったことです!!\n",
      "これは、私個人としては驚きましたが、他の方もおっしゃっているように、とても難しいことだと思います。でも、しっかりとした知識を身につけておけば大丈夫だと思いながら受けました。\n",
      "しかし、いざというときに役に立ちますし、自分の身を守るためにも役立つと思いますよ♪\n",
      "また、これから防災士を目指す人にとっては、大変ありがたい制度だと感じましたね☆\n",
      "防災士とは?\n",
      "防災士\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  富士山は\n",
      "perplexity:  4406.044921875\n",
      "time:  2.8311243057250977\n",
      "time/character:  0.003932117091284858\n",
      "output:  富士山は、標高1,058mの山頂から見える。\n",
      "\n",
      "脚注・出典\n",
      "\n",
      "関連項目 \n",
      " 日本の山一覧 (高さ順)\n",
      "\n",
      "外部リンク \n",
      " 静岡県/富士五湖国立公園 - 北アルプスの山々(北アルプス)|登山ガイド 東信版\n",
      " 南アルプス:南アルプス|山梨百名山会\n",
      "\n",
      "静岡県にある国指定の名勝 The Roman Catholic Diocese of San Pedro de la Cruz () is a Latin Church ecclesiastical territory or diocese in the Caribbean. It was erected on July 23, 1976 as an archdiocesan bishopric by Pope John Paul II and elevated to full metropolitan status with its own cathedrals; it has been called \"the most important church-state\" since independence from Spain after World War I when they were united under Spanish colonial rule over Trinidad during their civil war between them that same year. On December 4th, 1996 Archbishop José Antonio Soler announced his intention for relocating all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  質問: 今日の天気は? 回答:\n",
      "perplexity:  40.25303649902344\n",
      "time:  2.787745714187622\n",
      "time/character:  0.003551268425716716\n",
      "output:  質問: 今日の天気は? 回答: 今日は、雨が降ったり止んだりのお天気でした。\n",
      "投稿日時 - 投稿者: admin | 投稿日-2015年3月8日(木) 09時46分7秒 [通報] The Roman Catholic Diocese of San Pedro de Asís () (erected on February 1, 1995 as the Territorial Prelature for Our Lady of Guadalupe Parish), also known simply as El Salvador and its metropolitan area is a Latin American diocese. It was elevated to an archdiocese in May 2015 by Pope Francis after being consecrated bishopric since December 2014; it has been named one of two \"Roman Catholic bishops\" with this title having previously served under Cardinal José María del Carmen from July–August 2014 until his death at age nineteenty years prior. Its cathedral episcopal see serves all parts of Central America including Guatemala City where Archbishops are appointed every four months during\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  批判的な\n",
      "perplexity:  812.601318359375\n",
      "time:  2.809030294418335\n",
      "time/character:  0.0070756430589882496\n",
      "output:  批判的な意見\n",
      "2018/6/3(水) 15:47 [通報]\n",
      "> 「日本は、中国に負けた」と主張する人は、日本の歴史を知らない。\n",
      "> 日本が勝ったのは、中国の侵略行為だったのだから、それを正当化する根拠があるはずがない。\n",
      "> 中国の歴史認識や文化に対する理解も不足しているから、「日本が悪い」「中国人が悪い」という論調で片付けるしかなくなるだろうね。\n",
      "> > 「日本は、中国に対して勝てなかった」というのは嘘だとしても、それは間違いだと認めるべきだと思うよ。\n",
      "> 「日本は、中国に対し勝利しなかった」ということは、その証拠として、中国共産党による虐殺があったということを忘れてはならないと思うけどね。\n",
      "> 「日本は、中国に対して敗北した」とは言っていないけど、それを否定するのは間違っているよね?\n",
      "> 「日本は、中国に対して勝つことができた」というのが正しいかどうかは別にしても、それが真実なら、\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  大規模言語モデルは\n",
      "perplexity:  2274.221435546875\n",
      "time:  2.816113233566284\n",
      "time/character:  0.005953727766524914\n",
      "output:  大規模言語モデルは、2018年9月に発表された。\n",
      "\n",
      "概要 \n",
      "大規模な言語モデルの例として、C++やJavaなどのプログラミング言語で記述されたデータの処理方法が挙げられるが、これらの手法では、大量のデータを効率的に扱うためにメモリを大量に消費する傾向があるため、多くのアプリケーションに適用できるとは限らない。また、複数のプロセッサ間でのデータ転送も困難であるため、特定のアルゴリズムに依存している可能性がある(例えば、並行性制御など)。\n",
      "\n",
      "関連項目 \n",
      " C言語プログラミング\n",
      " Javaコード生成器 (JCL, JSP) - 並列計算を行うためのツール群\n",
      " Scala-like model of data structures and their applications.\n",
      "\n",
      "脚注・出典\n",
      "\n",
      "外部リンク \n",
      " https://www.jcllabs/encyclopedia/ja_JP/index.php?option=com_k2&view=itemlist&task=userid%3Analt+cp%5D%4F%6B%7E%BC%BD%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  AI研究の問題点は\n",
      "perplexity:  508.85589599609375\n",
      "time:  2.783825397491455\n",
      "time/character:  0.006504264947409941\n",
      "output:  AI研究の問題点は、その目的が「人間を機械化すること」である。\n",
      "\n",
      "この問題を解決するために開発されたのが、「人工知能技術を利用したロボット工学(Robotics)」という分野だ。「人間の知能と感情を統合するシステムを開発し、それによって人間らしさや魅力を表現すること」「人間性を高めるための仕組みの開発・開発を行うことで、人間性を向上させることができるのではないか?」といったコンセプトを掲げている。\n",
      "\n",
      "2019年4月時点で、約3,500人の研究者が開発に携わっているとされる。\n",
      "\n",
      "脚注\n",
      "\n",
      "外部リンク \n",
      " https://www.nycpdmxsfwzrqe.com/en-usualize_intelligentity/?view=itemlist&id=678 - Google News Japan (英語)\n",
      "https://twitter.com/ibuhitokotokoro?refactionID=1000000000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  化学研究の問題点は\n",
      "perplexity:  346.26922607421875\n",
      "time:  2.7964694499969482\n",
      "time/character:  0.0030330471258101393\n",
      "output:  化学研究の問題点は、その性質が解明されていないためである。\n",
      "\n",
      "脚注\n",
      "\n",
      "関連項目 \n",
      " 有機化学における化学反応の一覧 (List of reactions with known chemical elements)\n",
      "\n",
      "外部リンク \n",
      " Chem.Chem - Chemical synthesis and characterization, by David Axler-Scholeschmidt at the University of Chicago Press Center for Chemistry Research The Roman Catholic Diocese of San Pedro de la Cruz () is a Latin Church ecclesiastical territory or diocese in Nicaragua that was erected on April 15, 2006 as part of an agreement between Pope John Paul II to form one parish church within its own jurisdiction; it has been elevated since December 31st through January 7th accordingly under new bishopric changes made during his tenure there from February 8–9 until May 4, when he resigned due to ill health issues caused him into retirement after being diagnosed multiple times while still serving two years before dying suddenly upon receiving Holy Communion services priorities were not implemented properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  I have a\n",
      "perplexity:  231.47665405273438\n",
      "time:  2.792191505432129\n",
      "time/character:  0.003552406495460724\n",
      "output:  I have a problem with the scaling of your fingertip.\n",
      "I'm not sure what you are doing, but it is important to know how many people do this right now and also why they don’t like that because there wasn’t any other way around for me in my life... It makes sense when we were young enough so much time before our eyes could be seen as an unpleasant thing; if someone had been trying hard on somebody else who didn’t want us out loudly or did something wrong? The fact about being able to say goodbye does make one feel better than others think: “You can see yourself at all times” by John Lennon (1985) – which has become famous among fans since its release from his album \"The Way You Are\"... [Read more] 『THE BEST SELECTIONS』(ザ・ベストセレクションズ、原題:Best Selections From A-ha!/英題:BEST COLLECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  Functional polymers are\n",
      "perplexity:  279.80242919921875\n",
      "time:  2.8141486644744873\n",
      "time/character:  0.002343171244358441\n",
      "output:  Functional polymers are the most common types of organic chemical reaction.\n",
      "The main components in this process include: (a) synthesis, decarboxylation and reduction; (b), biocatalyst recycling processes such as catalyst-based conversion or hydrogenation/hydrogen transfer to a fuel cell for further processing by means other than heat generation from an oil tanker's boiler engine using solvent extraction methods like gasification techniques that can be used with petroleum products including gasoline engines which use water instead of air rather than electricity because they have been developed specifically at various times over time but not yet commercially available since it is still being manufactured under licence due to its high cost per unit volume compared to conventional diesel locomotives on their own design schemes during World War II until today all these technologies were replaced after production ended up having ceased altogether when new technology was introduced into commercial operation within one year following closure of operations worldwide through acquisition via private equity firm Sumitomo Chemical Co Ltd whereby some companies also acquired shares owned directly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatakeyama/miniconda3/envs/llmeval/lib/python3.11/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "input:  機能性高分子は\n",
      "perplexity:  5385.06640625\n",
      "time:  2.7773361206054688\n",
      "time/character:  0.005798196493957138\n",
      "output:  機能性高分子は、細胞の生存に必要なタンパク質を合成する。\n",
      "\n",
      "機能と構造 \n",
      "\n",
      "ヒトでは、抗腫瘍活性を有するポリペプチド(PPAR)が主に発現している。このポリペプチドには、免疫系や神経系の働きに関与し、がん抑制因子として作用することが知られており、その分子量は約10,5 kDaであると推定されている。また、これらのポリペプチドの中には、他の多くの薬剤との相互作用によってもたらされるものもあるため、それらに対する耐性を持つことが期待されている。さらに、ポリペプチドの構造中には、さまざまな種類の酵素が存在しており、それらの代謝産物を介して様々な生理的過程を経て生成されていくと考えられている。こうしたポリペプチドの機能的な性質から、ポリペプチドはその生体内における重要な構成要素となっていると考えられる。\n",
      "\n",
      "ポリペプチドは、細胞内の特定の組織で産生されたり、細胞外へ排出されて体内に吸収されたりすることで形成される。例えば、マウスを用いた研究によると、ポリペプチドはマウス胚において、細胞表面に存在する膜貫通性のタンパク質であり、細胞表面に存在している膜貫通\n",
      "-------\n",
      "input:  ホンダ フィット 販売\n",
      "perplexity:  384.00347900390625\n",
      "time:  2.7703893184661865\n",
      "time/character:  0.003515722485363181\n",
      "output:  ホンダ フィット 販売・詳細ページへ\n",
      "【送料無料】HONDA N-BOX+/Nボックスプラス専用フロアマット [プレミアムタイプ] カー用品 車用アクセサリー... The Roman Catholic Diocese of San Pedro de Asís () (erected on February 1, 2007) is a Latin American diocese in the ecclesiastical province and one of two coadjutor bishops. It was elevated to an archdiocesan bishopric by Pope Francis as part of its Apostolic Vicariate for El Salvador from July 31st through December 5th, 2019; it has been named Archbishop since January 4, 2026 due to COVID pandemics that forced him into retirement after being diagnosed with multiple myeloma during his tenure there between August–September 2020 until he resigned effective June 8, 2021 when Cardinal José Luis García announced plans were made regarding resumption of all missions at Santo Domingo instead of returning\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text_list=[\"今日はいい\",\n",
    "\"富士山は\",\n",
    "\"質問: 今日の天気は? 回答:\",\n",
    "\"批判的な\",\n",
    "\"大規模言語モデルは\",\n",
    "\"AI研究の問題点は\",\n",
    "\"化学研究の問題点は\",\n",
    "\"I have a\",\n",
    "\"Functional polymers are\",\n",
    "\"機能性高分子は\",           \n",
    "\"ホンダ フィット 販売\",\n",
    "]\n",
    "\n",
    "for text in text_list:\n",
    "    perp=perplexity(model,tokenizer,text)\n",
    "    s_time=time.time()\n",
    "    res=pipe(text)[0][\"generated_text\"]\n",
    "    consumed_time=time.time()-s_time\n",
    "    print(\"-------\")\n",
    "    print(\"input: \", text)\n",
    "    print(\"perplexity: \",perp)\n",
    "    print(\"time: \", consumed_time)\n",
    "    print(\"time/character: \", consumed_time/len(res))\n",
    "    print(\"output: \",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

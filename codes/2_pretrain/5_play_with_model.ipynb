{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#作ったモデルを動かしてみる\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "def perplexity(model, tokenizer, text) -> torch.Tensor:\n",
    "    tokenized_input = tokenizer.encode(\n",
    "        text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        output = model(tokenized_input, labels=tokenized_input)\n",
    "    ppl = torch.exp(output.loss)\n",
    "    return ppl.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../../models/hf\"\n",
    "model_path=\"../../models/hf_fin\"\n",
    "model_path=\"../../models/hf_fin_shuffle\"\n",
    "#model_path=\"../../models/hf_10000\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=pipeline('text-generation',model=model,tokenizer=tokenizer, max_new_tokens=200, repetition_penalty=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/setup/miniconda3/envs/scr/lib/python3.11/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "perplexity:  45.47639846801758\n",
      "output:  今日はいいのに。」\n",
      "「私たちが、自分を見つめてくれたことがあるんだからね...。そうですよねぇんでしたけど、僕らもみんなところへ行ってしまったんだからね。だからねえ、俺達には何かあればいいじゃないですよねぇんでした。でも、僕らはそれぞれ違和感なくやっているんだからね。」\n",
      "「僕らは、自分を見つめた人間ではなかった。僕らは、自分を見つめている人々であるべきだった。僕らは、自分を見つめる人間でありたいという気持ちもあるわけですよねぇんでした。そのため、僕らは、自分を見つめることによって、自分を見つめられる人間になるのだからね。」\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "perplexity:  187.1234588623047\n",
      "output:  富士山は、1980年代後半から20世紀初頭にかけての日本における「日本の歴史」を題材とした作品である。\n",
      "\n",
      "概要 \n",
      "『古事記』では、「大和国(奈良県)・紀伊国(大阪府)が平安時代末期頃まで遡るという説話があることで知られる。この時点においても、大和国には、大和国内部の地名や氏族などの氏神として崇拝されていたものの、その存在自体については諸説ある。また、大和国内部の地名や氏族などの氏神として崇敬されるようになったのは、鎌倉時代以降であり、それらのうち、大和国内部の氏神であったとする見方もある。なお、大和国内部の氏神としては、大和国内部の氏神としては\n",
      "-------\n",
      "perplexity:  177.24807739257812\n",
      "output:  I have a great deal of experience.\"\n",
      "\n",
      "In the early years, he was involved with several others and became an assistant to his brother-in-law James Craig (1853–60) who had been promoted by himself at St John's Cathedral from 1924 until his death on 7 September 1928. He died after being returned homeless for two months before it could be completely unearthed. His body is located nearby at Sydeney Road, Bridgend Avenues, London. The gravestone has three wall paintings: one that showcases \"The Greenwich Papers\"; both are famous for their works which were\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text_list=[\"今日はいい\",\n",
    "\"富士山は\",\n",
    "\"I have a\"           \n",
    "]\n",
    "\n",
    "for text in text_list:\n",
    "    perp=perplexity(model,tokenizer,text)\n",
    "    res=pipe(text)[0][\"generated_text\"]\n",
    "    print(\"-------\")\n",
    "    print(\"perplexity: \",perp)\n",
    "    print(\"output: \",res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

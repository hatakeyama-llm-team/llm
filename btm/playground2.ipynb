{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btmのrootingの練習をする\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer,pipeline\n",
    "import numpy as np\n",
    "\n",
    "from PPLMoE.MoEPipe import MoEPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hatakeyama/miniconda3/envs/llmeval/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "moe=MoEPipe()\n",
    "\n",
    "\n",
    "model_name_list =[ \n",
    "    #\"../models/hf/0401_270m_eng\",\n",
    "    \"../models/hf/0401_270m_web\",\n",
    "    \"../models/hf/0401_270m_fin\",\n",
    "    \"../models/hf/0405_2700m_clean_ja\",\n",
    "                  ]\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, device_map=\"auto\",\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    moe.append_ELM(model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----\n",
      "input:  hello, I'm John\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity list\n",
      "0 325.5\n",
      "1 192.0\n",
      "2 211.0\n",
      "model id 1 is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  hello, I'm John Doe.\"\n",
      " 1973: \"They are the ones who have been in charge of this country for so long and they don’t know how to do it anymore! They can be very good people but we need them more than ever before again... We will never see a better way out from here on with these two men as our leaders or their successor? The answer is no – that wasn‘ts what you were looking at when your bosses came\n",
      "\n",
      "\n",
      "-----\n",
      "input:  global warming \n",
      "perplexity list\n",
      "0 4404.0\n",
      "1 847.5\n",
      "2 239.0\n",
      "model id 2 is used\n",
      "response:  global warming as an Affairs, and there are not to be mind. In Proceedings of the Association for Computational Linguistics: Volume 1 (Long Papers)\n",
      "|style=\"text-align:center;background:#afe6babfcdhtml\" style=\"font-size:75%\">\n",
      "|-\n",
      "! 20th Century's Best Reason in Machine\n",
      "\n",
      "\n",
      "-----\n",
      "input:  英語: He is a good man. 日本語: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity list\n",
      "0 69.0\n",
      "1 45.625\n",
      "2 44.46875\n",
      "model id 2 is used\n",
      "response:  英語: He is a good man. 日本語: new supported by the people of most flowing, and which are not to be better for meanings in this papers only without that have researchers' (1987)\n",
      "|style=\"text-align:center;background:#afe6babpsyes/wheelthought \"reviewer\" style = \"white\" alignment & treatment atten\n",
      "\n",
      "\n",
      "-----\n",
      "input:  今日は晴れてるから\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity list\n",
      "0 956.5\n",
      "1 6772.0\n",
      "2 217.625\n",
      "model id 2 is used\n",
      "response:  今日は晴れてるから、もう帰らない。」\n",
      "「えゝ、さうかしら......」と、お民が云つた、「いやだわねエ?」と云つて、「へツて? 」といふ声で、「ぢゃあ、何んにも知らんよ!」\n",
      " お民も黙つてゐたのである。\n",
      "「あらア、今晩は寝ないんだもの――」とお民は何時の間になくなつた。\n",
      "「まア、御飯を頂戴して下さい\n",
      "\n",
      "\n",
      "-----\n",
      "input:  ブログを書きました\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity list\n",
      "0 446.5\n",
      "1 2064.0\n",
      "2 18400.0\n",
      "model id 0 is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  ブログを書きました。\n",
      "2018/9月3日(土)に、東京・渋谷のNHKホールで「第九」演奏会が開催されました。「第十回記念定期公演～合唱とオーケストラによる『第九』～」です。(写真は、当日の模様)。 【楽天市場】購入者さんの【送料無料】【中古】(ランク:B)(ブランドカナ):ルイヴィトン|バッグの通販\n",
      "選択中の条件:その他LOUIS VUITTONすべて解除\n",
      "4.57(6件)\n",
      "[クーポン利用]新品未使用\n",
      "\n",
      "\n",
      "-----\n",
      "input:  地球温暖化を防ぐに\n",
      "perplexity list\n",
      "0 1167.0\n",
      "1 2844.0\n",
      "2 18848.0\n",
      "model id 0 is used\n",
      "response:  地球温暖化を防ぐにはどうしたらいいか、という問題は、人類が解決しなければならない大きな課題です。 【楽天市場】購入者さんの【送料無料】【2ケースセット】(北海道・沖縄除く)ポッカサッポロ生ビール黒ラベル350ml×48本(1個)【イージャパンモール】[ビア](e-Japanmall)|みんなのレビュー・口コミ\n",
      "購入者さんの【送料無料...(e- Japanmall)のレビュー・口コミ情報|みんなのレビュー\n",
      "楽天市場トップ>みんなのレビュー・口コミ>【送料無料...のレビュー・口コミ\n",
      "\n",
      "\n",
      "-----\n",
      "input:  ガリレオによるピサの斜塔実験とは\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity list\n",
      "0 360.25\n",
      "1 1302.0\n",
      "2 1559.0\n",
      "model id 0 is used\n",
      "response:  ガリレオによるピサの斜塔実験とは、1960年8月24日にイタリア・トリノで行われた「ピサロ」という斜塔を地上から持ち上げる実験のこと。 【楽天市場】購入者さんの【送料無料】【中古】(ランク:B)ダンロップXXIO(ゼクシオ)(ドライバー)X-DRIVE357Vレディス右利きフェアウェイウッドFW XドライブカーボンゴルフクラブSecond Hand|みんなのレビュー・口コミ\n",
      "購入者さん評価5.00投稿日:20代/男性良い点値段が安いので\n",
      "\n",
      "\n",
      "-----\n",
      "input:  スーパーコンピューターの富岳は\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity list\n",
      "0 1328.0\n",
      "1 5524.0\n",
      "2 1577.0\n",
      "model id 0 is used\n",
      "response:  スーパーコンピューターの富岳は、パソコンやスマートフォンなどの電子機器をインターネットに接続するための無線LAN(Wi-Fi)機能を搭載しています。 「このたび、株式会社スクウェア・エニックスが運営を行うオンラインゲーム『ファイナルファンタジーXIV』において、『FINALFANTASY XIV Official Channel』(以下FF14公式チャンネルと記載します。『FFX IV』、略して『ffxiv』『エフエックスフォー)』を公開いたしましたことをお知らせいたします」\n",
      "また、「ファイナルファンタジーXIV」、「ファイナルファンタジーXV」(2018年発売予定予定)、\n"
     ]
    }
   ],
   "source": [
    "#moe.set_coefs(np.array([1,0.5,1]))\n",
    "moe.set_coefs([1,1,1])\n",
    "\n",
    "text_list=[\n",
    "    \"hello, I'm John\",\n",
    "    \"global warming \",\n",
    "    \"英語: He is a good man. 日本語: \",\n",
    "    \"今日は晴れてるから\",\n",
    "    \"ブログを書きました\",\n",
    "    \"地球温暖化を防ぐに\",\n",
    "    \"ガリレオによるピサの斜塔実験とは\",\n",
    "    \"スーパーコンピューターの富岳は\",\n",
    "]\n",
    "response_list=[]\n",
    "ppl_list=[]\n",
    "model_list=[]\n",
    "for text in text_list:\n",
    "    print(\"\\n\\n-----\")\n",
    "    print(\"input: \", text)\n",
    "    response,ppl,model_id=moe.ask(text)\n",
    "    print(\"response: \",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
